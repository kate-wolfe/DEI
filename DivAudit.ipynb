{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10jRuTAGz_Hk2DKVaQY632DQ8ceVoNgl8",
      "authorship_tag": "ABX9TyOp9uulyPHODl7sBCTRDFHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kate-wolfe/DEI/blob/main/DivAudit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h83zZ3exPFE"
      },
      "source": [
        "Mount Google Drive. This can also be done by clicking on the folder on the left and choosing the \"mount drive\" option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zULIJNwPc3ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc07dafe-c5f1-4a79-e2c6-208b800db286"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iOo08TKcYs"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4xsUCieKeV4"
      },
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "import datetime\n",
        "import pytz\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocJbKfsYxg6u"
      },
      "source": [
        "Read CSVs in as dataframes using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDESwhimwUf3"
      },
      "source": [
        "dfPhraseLoad = pd.read_csv('/content/drive/MyDrive/Div Audit 11-10-22/phraseALL_11-10-22.csv', usecols=['record_num', 'is_permuted', 'index_entry'], dtype={'record_num':int, 'is_permuted': str, 'index_entry': str})\n",
        "dfBibLoad = pd.read_csv('/content/drive/MyDrive/Div Audit 11-10-22/Bibs_11-10-22.csv', usecols=['record_num', 'material_type_name'], dtype={'record_num': int, 'material_type_name': str})\n",
        "dfItemLoad = pd.read_csv('/content/drive/MyDrive/Div Audit 11-10-22/Items_11-10-22.csv', usecols=['record_num', 'creation_date_gmt', 'call_number_norm', 'location_code', 'price', 'checkout_total'], dtype={'record_num': int, 'creation_date_gmt': str, 'call_number_norm': str, 'location_code': str, 'price': float, 'checkout_total': int})\n",
        "dfLinkLoad = pd.read_csv('/content/drive/MyDrive/Div Audit 11-10-22/RecordLink_11-10-22.csv', usecols=['bib_record_num', 'item_record_num'], dtype={'bib_record_num': int, 'item_record_num': int})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyJgFCCwHisY"
      },
      "source": [
        "dfPhraseFull keeps the bib record numbers so that it can merge with the bib report later. dfPhrase pares down the report so that lookups are faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISzoAco3H4wd"
      },
      "source": [
        "dfPhraseFull = dfPhraseLoad.loc[dfPhraseLoad['is_permuted'].isnull()].reset_index(drop=True)\n",
        "dfPhraseFull = dfPhraseFull.drop(['is_permuted'], axis=1)\n",
        "\n",
        "dfPhrase = dfPhraseFull.drop(['record_num'], axis=1)\n",
        "dfPhrase = dfPhrase.drop_duplicates(subset=['index_entry'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCASanVJk15"
      },
      "source": [
        "Create regex patterns and compile them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV8qdAKgJX9V"
      },
      "source": [
        "rel_buddPat = r'(\\bzen\\b)|(dalai lama)|(buddhis)'\n",
        "rel_hinduPat = r'(\\bhindu(?!(stan|\\skush)))|(divali)|(\\bholi\\b)|(bhagavadgita)|(upanishads)'\n",
        "rel_agnosPat = r'(agnosticism)|(atheism)|(secularism)'\n",
        "rel_chrisPat = r'(shaker)|(new testament)|(protestant)|(bibl(e|ical))|(nativity)|(adventis)|(mormon)|(baptist)|(catholic)|(methodis)|(pentecost)|(episcopal)|(lutheran)|(clergy)|(church)|(evangelicalism)|(christianity)|(easter\\b)|(christmas)|(noahs ark)|(christian(?!.*\\d{4}))'\n",
        "rel_islamPat = r'((?<!terrorism.*)(islam(?!.*(fundamentalism|terrorism))))|(\\bsufi(sm)?)|(ramadan)|(id al (fitr\\b)|(\\badha\\b))|(quran)|(sunnites)|(shiah)|(muslim)|(mosques)|(qawwali)'\n",
        "rel_paganPat = r'(paganism)|(neopagans)|(wicca)'\n",
        "rel_jewPat = r'(jews)|(jewish)|(judaism)|(holocaust)|(hanukkah)|(purim)|(passover)|(zionis)|(hasid)|(antisemitism)|(rosh hashanah)|(yom kippur)|(sabbath(?!day))|(sukkot)|(pentateuch)|(synagogue)|(yiddish)|(hebrew)'\n",
        "rel_genPat = r'(\\breligio)'\n",
        "\n",
        "classPat = r'(working class)|(social ((status)|(mobility)|(class)|(stratification)))|(standard of living)|(poor)|(\\bcaste\\b)|(classism)'\n",
        "\n",
        "nat_sasiaPat = r'(south asia)|(indic\\b)|(\\bindia\\b)|(east indian)|(bengali)|(bangladesh)|(?<!everest.*)(nepal(?!.*everest))|(sri lanka)|(bhutan)'\n",
        "nat_easiaPat = r'(east asia)|(asian americans)|(?<!everest).*(chin(a(?!\\sfictitious)|ese)(?!.*everest))|(japan)|(korea)|(taiwan)|(vietnam(?! war))|(cambodia)|(mongolia)|(lao(s|tian))|(myanmar)|(malay)|(thai)|(philippin)|(filipino)|(indonesia)|(polynesia)|(brunei)|(east timor)|(pacific island)|(tibet autonomous)|(hmong)'\n",
        "nat_indigPat = r'(indigenous)|(aboriginal)|(american indian)|((?<!east(ern)\\s)\\bindians(?!\\sbaseball))|(apache)|(cherokee)|(navajo)|(trail of tears)|(aztecs)|(indian art)|(maya(s|n))|(ojibwa)|(iroquois)|(nez perce)|(shoshoni)|(pueblo indian)|(seminole)|(eskimos)|(inuit)|(inca(s|n))|(algonquia?n)|(arctic peoples)|(aleut)'\n",
        "nat_arabPat = r'(\\barab)|(afghan(?!\\swar))|(?<!k2.*)(pakistan(?!.*k2))|(middle east)|(palestin)|(bedouin)|(israel)|(saudi)|(yemen)|(iraq(?!\\swar))|(\\biran\\b)|(egypt(?!ologists))|(leban(on|ese))|(qatar)|(syria)|((?<!wild )turk((ish|ey(?!(s| hunting)))?)\\b)|(kurdis)|(bahrain)|(cyprus)|(kuwait)|(\\boman)|(?<!(belfort|lacey|romero|peele|kisner|lebowitz|miller|myles|reid|rubin|schnitzer|shakoor|sonnenblick|spieth|john|davis|clara|richard) )jordan(?! (ruth|fisher|vernon|michael|barbara|robbie|carol|john|david|grace|family|schnitzer|hal|louis|karl|raisa|dorothy|clarence|bruce|billy|andrew|b\\b|wong|will|ted|steve|robert|pete|pat|mattie|marsh|leslie|june|joseph|hamilton|zach|teresa|bella|eben))'\n",
        "nat_hispPat = r'(hispanic)|(?<!new\\s)(mexic)|(latin america)|(cuba(?!n\\smissile))|(puerto ric)|(dominican)|(el salvador)|(salvadoran)|(argentin)|(bolivia)|(chile)|(colombia)|(costa rica)|(ecuador)|(equatorial guinea)|(guatemala)|(hondura)|(nicaragua)|(panama)|(paragua)|(peru)|(spain)|(spaniard)|(spanish)|(urugua)|(venezuela)|(brazil)|(guiana)|(guadaloup)|(martinique)|(saint barthelemy)|(saint martin)'\n",
        "nat_blackPat = r'(men black)|(\\bafro)|(haiti)|(blacks(?!mith))|(africa)|(black (nationalism|panther party|power|muslim|lives))|(harlem renaissance)|(abolition)|(segregation)|(?<!(rome)|(italy)|(egypt)).*(slave(s|(ry))(?!(rome)|(egypt)|(italy)))|(slave trade)|(emancipation)|(underground railroad)|(apartheid)|(jamaica)|(nigeria)|(ethiopia)|(congo)|((?<!kilmanjaro.*)(tanzania(?!.*kilmanjaro)))|(kenya)|(uganda)|(sudan)|(ghana)|(cameroon)|(madagascar)|(mozambique)|(angola)|(niger)|(ivory coast)|(\\bmali\\b)|(burkina faso)|(malawi)|(somalia)|(zambia)|(senegal)|(zimbabw)|(rwanda)|(eritrea)|(guinea (?!pig))|(benin\\b)|(burundi)|(sierra leone)|(\\btogo\\b)|(liberia)|(mauritania)|(\\bgabon)|(namibia)|(botswana)|(lesotho)|(gambia)|(eswatini)|(djibouti)|(\\btutsi\\b)|((?<!(johnson|foster|gardenier|gibbs|hurley|jenkins|kerley|kister|rje) )\\bchad\\b)'\n",
        "nat_multiPat = r'(multicultural)|(interracial)|(cross cultural)|(diasporas)|((?<!sexual\\s)minorities)|(ethnic identity)|((race|ethnic) relations)|(racially mixed)|(bilingual)|(passing identity)' \n",
        "\n",
        "dis_blindPat = r'(blind)'\n",
        "dis_deafPat = r'(deaf)'\n",
        "dis_ampPat = r'(amputees)'\n",
        "dis_otherPat = r'((?<!recordings for people.*)disabilit)|(terminally ill)|(patients)'\n",
        "\n",
        "men_autismPat = r'(aspergers)|(autis(m|tic))'\n",
        "men_anxPat = r'(anxiety)'\n",
        "men_ocdPat = r'(compulsive)'\n",
        "men_schizoPat = r'(schizophrenia)'\n",
        "men_eatingPat = r'(eating disorders)'\n",
        "men_moodPat = r'(suicid)|(depressi(?!ons))|(stress (psychology|disorder))|(postpartum psychiatric disorder)|(seasonal affective disorder)'\n",
        "men_otherPat = r'(neurobehavioral)|(neuropsychology)|(neurodiversity)|(brain variation)|(personality disorder)|(mentally ill)|(acceptance)|(mental (health|illness|healing))|(resilience personality)|(self (esteem|confidence|realization|perception|actualization|management|destructive|control))|(emotional problems)|(mindfulness)|(psychic trauma)|((?<!(homo|islamo|trans|xeno))phobia)'\n",
        "\n",
        "add_gamblePat = r'(gamblers)'\n",
        "add_drugPat = r'(drug use)|(drug abuse)|((substance|medication|opioid|oxycodone|cocaine|marijuana|opium|phetamine|drug|morphine|heroin)\\sabuse)'\n",
        "add_alcoPat = r'(alcoholi(?!c beverages))|(binge drinking)'\n",
        "add_otherPat = r'((?<!relationship\\s)addiction)|(addicts)'\n",
        "\n",
        "vio_genPat = r'(harassment)|(victims of)|(bullying)|(aggressiveness)|(violent crimes)|((?<!non)violence)|(crimes against)'\n",
        "vio_hatePat = r'(hate crime)|(internment)'\n",
        "vio_police = r'(police brutality)'\n",
        "vio_traffickPat = r'((human|child)\\strafficking)|(kidnapping)'\n",
        "vio_murderPat = r'(genocide)|((?<!(su)|(herb)|(pest))icide)|(suicide bombers)|(murder)'\n",
        "vio_torturePat = r'((?<!psychological\\s)torture)'\n",
        "vio_rapePat = r'(\\brape)'\n",
        "vio_abusePat = r'((?<!(substance|medication|opioid|oxycodone|cocaine|marijuana|opium|phetamine|drug|morphine|heroin))\\sabuse)'\n",
        "\n",
        "equ_phobiaPat = r'(((islamo)|(xeno)|(trans))phobia)'\n",
        "equ_racerelPat = r'(racial profiling)|(ku klux klan)|(eugenics)|(race awareness)|(equality)|(racism)|(colorism)'\n",
        "equ_immigrantPat = r'(immigra)|(refugee)'\n",
        "equ_genderPat = r'(feminis)|(womens rights)|(sexism)|(suffrag)|(sex role)|(abortion)|(sexual harassment)'\n",
        "equ_climatePat = r'(sustainable development)|(environmental)|(climatic changes)'\n",
        "equ_otherPat = r'(persecution)|(activis)|(social psychology)|(social status)|(political prisoners)|((?<!fugitives from )justice(?!(s of the peace)|(\\s(league|society|donald))))|(social (change)|(movements)|(problems)|(reformers)|(responsibilit)|(conditions))|(discrimination)|(poverty)|(((pro choice)|(labor)|(gay liberation)|(anti nazi)|(black lives matter)) movement)|((human|civil) rights)|(prejudice)|(protest movements)|(homeless)|(public (health|welfare))'\n",
        "\n",
        "lgbt_gayPat = r'(gay(s|\\b(?!(head|john))))|(homosexual)|(lesbian)|(stonewall riots)'\n",
        "lgbt_bisexPat = r'(bisexual)'\n",
        "lgbt_asexPat = r'(asexual)'\n",
        "lgbt_interPat = r'(intersex)'\n",
        "lgbt_transPat = r'(trans(gen|sex|phobia))'\n",
        "lgbt_otherPat = r'(sexual minorities)|(gender)|(masculinity)|(femininity)|(drag show)|(male impersonator)|(queer)|(lgbtq)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4_Qzhavi0CZ"
      },
      "source": [
        "BUDcomp = re.compile(rel_buddPat)\n",
        "HINcomp = re.compile(rel_hinduPat)\n",
        "AGNcomp = re.compile(rel_agnosPat)\n",
        "CHRcomp = re.compile(rel_chrisPat)\n",
        "ISLcomp = re.compile(rel_islamPat)\n",
        "PAGcomp = re.compile(rel_paganPat)\n",
        "JEWcomp = re.compile(rel_jewPat)\n",
        "RELcomp = re.compile(rel_genPat)\n",
        "\n",
        "CLAcomp = re.compile(classPat)\n",
        "\n",
        "SAScomp = re.compile(nat_sasiaPat)\n",
        "EAScomp = re.compile(nat_easiaPat)\n",
        "INDcomp = re.compile(nat_indigPat)\n",
        "HIScomp = re.compile(nat_hispPat)\n",
        "BLAcomp = re.compile(nat_blackPat)\n",
        "ARAcomp = re.compile(nat_arabPat)\n",
        "MULcomp = re.compile(nat_multiPat)\n",
        "\n",
        "BLIcomp = re.compile(dis_blindPat)\n",
        "DEAcomp = re.compile(dis_deafPat)\n",
        "AMPcomp = re.compile(dis_ampPat)\n",
        "DIScomp = re.compile(dis_otherPat)\n",
        "\n",
        "AUTcomp = re.compile(men_autismPat)\n",
        "ANXcomp = re.compile(men_anxPat)\n",
        "OCDcomp = re.compile(men_ocdPat)\n",
        "SCHcomp = re.compile(men_schizoPat)\n",
        "EATcomp = re.compile(men_eatingPat)\n",
        "DEPcomp = re.compile(men_moodPat)\n",
        "MENcomp = re.compile(men_otherPat)\n",
        "\n",
        "GAMcomp = re.compile(add_gamblePat)\n",
        "DRUcomp = re.compile(add_drugPat)\n",
        "ALCcomp = re.compile(add_alcoPat)\n",
        "ADDcomp = re.compile(add_otherPat)\n",
        "\n",
        "VIOcomp = re.compile(vio_genPat)\n",
        "HATcomp = re.compile(vio_hatePat)\n",
        "POLcomp = re.compile(vio_police)\n",
        "TRAcomp = re.compile(vio_traffickPat)\n",
        "MURcomp = re.compile(vio_murderPat)\n",
        "TORcomp = re.compile(vio_torturePat)\n",
        "RAPcomp = re.compile(vio_rapePat)\n",
        "ABUcomp = re.compile(vio_abusePat)\n",
        "\n",
        "PHOcomp = re.compile(equ_phobiaPat)\n",
        "SOCcomp = re.compile(equ_racerelPat)\n",
        "IMMcomp = re.compile(equ_immigrantPat)\n",
        "GENcomp = re.compile(equ_genderPat)\n",
        "CLIcomp = re.compile(equ_climatePat)\n",
        "EQUcomp = re.compile(equ_otherPat)\n",
        "\n",
        "GAYcomp = re.compile(lgbt_gayPat)\n",
        "BIScomp = re.compile(lgbt_bisexPat)\n",
        "ASEcomp = re.compile(lgbt_asexPat)\n",
        "INTcomp = re.compile(lgbt_interPat)\n",
        "TNScomp = re.compile(lgbt_transPat)\n",
        "LGBcomp = re.compile(lgbt_otherPat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPPseXqiQpjz"
      },
      "source": [
        "Initialize lists for categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7AQ-WtRlE4Y"
      },
      "source": [
        "BUDlist = []\n",
        "HINlist = []\n",
        "AGNlist = []\n",
        "CHRlist = []\n",
        "ISLlist = []\n",
        "PAGlist = []\n",
        "JEWlist = []\n",
        "RELlist = []\n",
        "\n",
        "CLAlist = []\n",
        "\n",
        "SASlist = []\n",
        "EASlist = []\n",
        "INDlist = []\n",
        "HISlist = []\n",
        "BLAlist = []\n",
        "ARAlist = []\n",
        "MULlist = []\n",
        "\n",
        "BLIlist = []\n",
        "DEAlist = []\n",
        "AMPlist = []\n",
        "DISlist = []\n",
        "\n",
        "AUTlist = []\n",
        "ANXlist = []\n",
        "OCDlist = []\n",
        "SCHlist = []\n",
        "EATlist = []\n",
        "DEPlist = []\n",
        "MENlist = []\n",
        "\n",
        "GAMlist = []\n",
        "DRUlist = []\n",
        "ALClist = []\n",
        "ADDlist = []\n",
        "\n",
        "VIOlist = []\n",
        "HATlist = []\n",
        "POLlist = []\n",
        "TRAlist = []\n",
        "MURlist = []\n",
        "TORlist = []\n",
        "RAPlist = []\n",
        "ABUlist = []\n",
        "\n",
        "PHOlist = []\n",
        "SOClist = []\n",
        "IMMlist = []\n",
        "GENlist = []\n",
        "CLIlist = []\n",
        "EQUlist = []\n",
        "\n",
        "GAYlist = []\n",
        "BISlist = []\n",
        "ASElist = []\n",
        "INTlist = []\n",
        "TNSlist = []\n",
        "LGBlist = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka-RPDQaPyXY"
      },
      "source": [
        "Create columns with boolean values for whether that category shows up in the subject heading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnK2A6mflqVg"
      },
      "source": [
        "BUDlist = [int(bool(BUDcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "HINlist = [int(bool(HINcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "AGNlist = [int(bool(AGNcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "CHRlist = [int(bool(CHRcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ISLlist = [int(bool(ISLcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "PAGlist = [int(bool(PAGcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "JEWlist = [int(bool(JEWcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "RELlist = [int(bool(RELcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "CLAlist = [int(bool(CLAcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "SASlist = [int(bool(SAScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "EASlist = [int(bool(EAScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "INDlist = [int(bool(INDcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "HISlist = [int(bool(HIScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ARAlist = [int(bool(ARAcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "BLAlist = [int(bool(BLAcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "MULlist = [int(bool(MULcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "BLIlist = [int(bool(BLIcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "DEAlist = [int(bool(DEAcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "AMPlist = [int(bool(AMPcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "DISlist = [int(bool(DIScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "AUTlist = [int(bool(AUTcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ANXlist = [int(bool(ANXcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "OCDlist = [int(bool(OCDcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "SCHlist = [int(bool(SCHcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "EATlist = [int(bool(EATcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "DEPlist = [int(bool(DEPcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "MENlist = [int(bool(MENcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "GAMlist = [int(bool(GAMcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "DRUlist = [int(bool(DRUcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ALClist = [int(bool(ALCcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ADDlist = [int(bool(ADDcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "VIOlist = [int(bool(VIOcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "HATlist = [int(bool(HATcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "POLlist = [int(bool(POLcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "TRAlist = [int(bool(TRAcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "MURlist = [int(bool(MURcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "TORlist = [int(bool(TORcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "RAPlist = [int(bool(RAPcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ABUlist = [int(bool(ABUcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "PHOlist = [int(bool(PHOcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "SOClist = [int(bool(SOCcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "IMMlist = [int(bool(IMMcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "GENlist = [int(bool(GENcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "CLIlist = [int(bool(CLIcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "EQUlist = [int(bool(EQUcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "\n",
        "GAYlist = [int(bool(GAYcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "BISlist = [int(bool(BIScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "ASElist = [int(bool(ASEcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "INTlist = [int(bool(INTcomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "TNSlist = [int(bool(TNScomp.search(x))) for x in dfPhrase['index_entry']]\n",
        "LGBlist = [int(bool(LGBcomp.search(x))) for x in dfPhrase['index_entry']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHsXMyXYRbbt"
      },
      "source": [
        "Convert lists into dataframe columns for dfPhrase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F56vd9pPmqlr"
      },
      "source": [
        "dfPhrase['Religion_Buddhism'] = BUDlist\n",
        "dfPhrase['Religion_Hinduism'] = HINlist\n",
        "dfPhrase['Religion_Atheism'] = AGNlist\n",
        "dfPhrase['Religion_Christianity'] = CHRlist\n",
        "dfPhrase['Religion_Islam'] = ISLlist\n",
        "dfPhrase['Religion_Paganism'] = PAGlist\n",
        "dfPhrase['Religion_Judaism'] = JEWlist\n",
        "dfPhrase['Religion_General'] = RELlist\n",
        "\n",
        "dfPhrase['Class'] = CLAlist\n",
        "\n",
        "dfPhrase['Culture_SouthAsia'] = SASlist\n",
        "dfPhrase['Culture_EastAsia'] = EASlist\n",
        "dfPhrase['Culture_Indigenous'] = INDlist\n",
        "dfPhrase['Culture_Hispanic'] = HISlist\n",
        "dfPhrase['Culture_Black'] = BLAlist\n",
        "dfPhrase['Culture_Arab'] = ARAlist\n",
        "dfPhrase['Culture_Multicultural'] = MULlist\n",
        "\n",
        "dfPhrase['Disability_Blind'] = BLIlist\n",
        "dfPhrase['Disability_Deaf'] = DEAlist\n",
        "dfPhrase['Disability_Amputee'] = AMPlist\n",
        "dfPhrase['Disability_General'] = DISlist\n",
        "\n",
        "dfPhrase['Mental_Autism'] = AUTlist\n",
        "dfPhrase['Mental_Anxiety'] = ANXlist\n",
        "dfPhrase['Mental_Compulsive'] = OCDlist\n",
        "dfPhrase['Mental_Schizophrenia'] = SCHlist\n",
        "dfPhrase['Mental_Eating'] = EATlist\n",
        "dfPhrase['Mental_Depression'] = DEPlist\n",
        "dfPhrase['Mental_General'] = MENlist\n",
        "\n",
        "dfPhrase['Addiction_Gambling'] = GAMlist\n",
        "dfPhrase['Addiction_Drugs'] = DRUlist\n",
        "dfPhrase['Addiction_Alcohol'] = ALClist\n",
        "dfPhrase['Addiction_General'] = ADDlist\n",
        "\n",
        "dfPhrase['Violence_General'] = VIOlist\n",
        "dfPhrase['Violence_HateCrimes'] = HATlist\n",
        "dfPhrase['Violence_PoliceBrutality'] = POLlist\n",
        "dfPhrase['Violence_Trafficking'] = TRAlist\n",
        "dfPhrase['Violence_Murder'] = MURlist\n",
        "dfPhrase['Violence_Torture'] = TORlist\n",
        "dfPhrase['Violence_Rape'] = RAPlist\n",
        "dfPhrase['Violence_Abuse'] = ABUlist\n",
        "\n",
        "dfPhrase['Equity_Phobias'] = PHOlist\n",
        "dfPhrase['Equity_Social'] = SOClist\n",
        "dfPhrase['Equity_Immigration'] = IMMlist\n",
        "dfPhrase['Equity_Gender'] = GENlist\n",
        "dfPhrase['Equity_Climate'] = CLIlist\n",
        "dfPhrase['Equity_General'] = EQUlist\n",
        "\n",
        "dfPhrase['LGBT_Gay'] = GAYlist\n",
        "dfPhrase['LGBT_Bisexual'] = BISlist\n",
        "dfPhrase['LGBT_Asexual'] = ASElist\n",
        "dfPhrase['LGBT_Intersex'] = INTlist\n",
        "dfPhrase['LGBT_Trans'] = TNSlist\n",
        "dfPhrase['LGBT_General'] = LGBlist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Ca3S97TKY1"
      },
      "source": [
        "Export boolean dataframe to csv to check whether regex is working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfmMUzpCTJzn"
      },
      "source": [
        "dfPhrase.to_csv('drive/My Drive/Div Audit 11-10-22/phraseBools_11-10-22.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cn_BrBNUPwK"
      },
      "source": [
        "Set up bib record doc: combine and filter material types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qA6xLPhUVM8"
      },
      "source": [
        "dfBib = dfBibLoad.replace({'material_type_name':{'BLU-RAY':'Movie', 'DVD OR VCD':'Movie', 'JUV READALONG':'Book', 'BOOK':'Book', 'LARGE PRINT':'Book', 'PLAYAWAY AUDIOBOOK':'Audiobook', 'SPOKEN CD':'Audiobook'}})\n",
        "dfBib = dfBib.loc[dfBib['material_type_name'].isin(['Book','Movie','Audiobook'])].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZI89wbuVFkE"
      },
      "source": [
        "Time to merge stuff. Start by merging the two phrase dataframes (like a vlookup). Then the phrase (subject heading) column can be dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo7L6wNYVOhw"
      },
      "source": [
        "newPhrase = pd.merge(dfPhraseFull, dfPhrase, on='index_entry')\n",
        "newPhrase = newPhrase.drop(['index_entry'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlOS0TGIWdQQ"
      },
      "source": [
        "Now merge phrase with bib records. Condense the new dataframe using groupby. After this you can try to use the highest count in a column to assign a primary category. But we will move on for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZhrG7ZRWHEv"
      },
      "source": [
        "bibSubjects = pd.merge(newPhrase, dfBib, on='record_num')\n",
        "bibSubjectsCond = bibSubjects.groupby(['record_num','material_type_name']).sum().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "religionList = ['Religion_Buddhism', 'Religion_Hinduism', 'Religion_Atheism', 'Religion_Christianity', 'Religion_Islam', 'Religion_Paganism', 'Religion_Judaism', 'Religion_General']\n",
        "classList = ['Class']\n",
        "cultureList = ['Culture_SouthAsia', 'Culture_EastAsia', 'Culture_Indigenous', 'Culture_Hispanic', 'Culture_Arab', 'Culture_Black', 'Culture_Multicultural']\n",
        "disableList = ['Disability_Blind', 'Disability_Deaf', 'Disability_Amputee', 'Disability_General']\n",
        "mentalList = ['Mental_Autism', 'Mental_Anxiety', 'Mental_Compulsive', 'Mental_Schizophrenia', 'Mental_Eating', 'Mental_Depression', 'Mental_General']\n",
        "addictList = ['Addiction_Gambling', 'Addiction_Drugs', 'Addiction_Alcohol', 'Addiction_General']\n",
        "violenceList = ['Violence_General', 'Violence_HateCrimes', 'Violence_PoliceBrutality', 'Violence_Trafficking', 'Violence_Murder', 'Violence_Torture', 'Violence_Rape', 'Violence_Abuse']\n",
        "equityList = ['Equity_Phobias', 'Equity_Social', 'Equity_Immigration', 'Equity_Gender', 'Equity_Climate', 'Equity_General']\n",
        "lgbtList = ['LGBT_Gay', 'LGBT_Bisexual', 'LGBT_Asexual', 'LGBT_Intersex', 'LGBT_Trans', 'LGBT_General']\n",
        "\n",
        "catList = ['Religion_Buddhism', 'Religion_Hinduism', 'Religion_Atheism', 'Religion_Christianity', 'Religion_Islam', 'Religion_Paganism', 'Religion_Judaism', 'Religion_General', 'Class', 'Culture_SouthAsia', 'Culture_EastAsia', 'Culture_Indigenous', 'Culture_Hispanic', 'Culture_Black', 'Culture_Multicultural', 'Disability_Blind', 'Disability_Deaf', 'Disability_Amputee', 'Disability_General', 'Mental_Autism', 'Mental_Anxiety', 'Mental_Compulsive', 'Mental_Schizophrenia', 'Mental_Eating', 'Mental_Depression', 'Mental_General', 'Addiction_Gambling', 'Addiction_Drugs', 'Addiction_Alcohol', 'Addiction_General', 'Violence_General', 'Violence_HateCrimes', 'Violence_PoliceBrutality', 'Violence_Trafficking', 'Violence_Murder', 'Violence_Torture', 'Violence_Rape', 'Violence_Abuse', 'Equity_Phobias', 'Equity_Social', 'Equity_Immigration', 'Equity_Gender', 'Equity_Climate', 'Equity_General', 'LGBT_Gay', 'LGBT_Bisexual', 'LGBT_Asexual', 'LGBT_Intersex', 'LGBT_Trans', 'LGBT_General']"
      ],
      "metadata": {
        "id": "0LR86WWiplFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relArr = bibSubjectsCond[religionList].to_numpy()\n",
        "sumRelArr = np.sum(relArr, axis=1).tolist()\n",
        "\n",
        "relOutput = []\n",
        "relOutput = ['Unique Religion' if sumRelArr[x] > 0 else 'Not Religion' for x in range(len(sumRelArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Religion'] = relOutput"
      ],
      "metadata": {
        "id": "3DeL1C6Lv2nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classArr = bibSubjectsCond[classList].to_numpy()\n",
        "sumClaArr = np.sum(classArr, axis=1).tolist()\n",
        "\n",
        "claOutput = []\n",
        "claOutput = ['Unique Class' if sumClaArr[x] > 0 else 'Not Class' for x in range(len(sumClaArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Class'] = claOutput"
      ],
      "metadata": {
        "id": "WnbHaBYQxUa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cultArr = bibSubjectsCond[cultureList].to_numpy()\n",
        "sumCultArr = np.sum(cultArr, axis=1).tolist()\n",
        "\n",
        "cultOutput = []\n",
        "cultOutput = ['Unique Culture' if sumCultArr[x] > 0 else 'Not Culture' for x in range(len(sumCultArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Culture'] = cultOutput"
      ],
      "metadata": {
        "id": "xXELHYdexiV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disArr = bibSubjectsCond[disableList].to_numpy()\n",
        "sumDisArr = np.sum(disArr, axis=1).tolist()\n",
        "\n",
        "disOutput = []\n",
        "disOutput = ['Unique Disability' if sumDisArr[x] > 0 else 'Not Disability' for x in range(len(sumDisArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Disability'] = disOutput"
      ],
      "metadata": {
        "id": "rj8A9ak_xwC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menArr = bibSubjectsCond[mentalList].to_numpy()\n",
        "sumMenArr = np.sum(menArr, axis=1).tolist()\n",
        "\n",
        "menOutput = []\n",
        "menOutput = ['Unique Mental' if sumMenArr[x] > 0 else 'Not Mental' for x in range(len(sumMenArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Mental'] = menOutput"
      ],
      "metadata": {
        "id": "UkTC7_tCyv_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addArr = bibSubjectsCond[addictList].to_numpy()\n",
        "sumAddArr = np.sum(addArr, axis=1).tolist()\n",
        "\n",
        "addOutput = []\n",
        "addOutput = ['Unique Addiction' if sumAddArr[x] > 0 else 'Not Addiction' for x in range(len(sumAddArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Addiction'] = addOutput"
      ],
      "metadata": {
        "id": "m7mlZo0WzCdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vioArr = bibSubjectsCond[violenceList].to_numpy()\n",
        "sumVioArr = np.sum(vioArr, axis=1).tolist()\n",
        "\n",
        "vioOutput = []\n",
        "vioOutput = ['Unique Violence' if sumVioArr[x] > 0 else 'Not Violence' for x in range(len(sumVioArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Violence'] = vioOutput"
      ],
      "metadata": {
        "id": "e_FJTOjtzPG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equArr = bibSubjectsCond[equityList].to_numpy()\n",
        "sumEquArr = np.sum(equArr, axis=1).tolist()\n",
        "\n",
        "equOutput = []\n",
        "equOutput = ['Unique Equity' if sumEquArr[x] > 0 else 'Not Equity' for x in range(len(sumEquArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Equity'] = equOutput"
      ],
      "metadata": {
        "id": "vqYLkdZszfh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbtArr = bibSubjectsCond[lgbtList].to_numpy()\n",
        "sumLGBTArr = np.sum(lgbtArr, axis=1).tolist()\n",
        "\n",
        "lgbtOutput = []\n",
        "lgbtOutput = ['Unique LGBT' if sumLGBTArr[x] > 0 else 'Not LGBT' for x in range(len(sumLGBTArr))]\n",
        "\n",
        "bibSubjectsCond['Unique LGBT'] = lgbtOutput"
      ],
      "metadata": {
        "id": "HTrTcASszzUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catArr = bibSubjectsCond[catList].to_numpy()\n",
        "sumCatArr = np.sum(catArr, axis=1).tolist()\n",
        "\n",
        "divList = []\n",
        "divList = ['Unique Diverse' if sumCatArr[x] > 0 else 'Not Diverse' for x in range(len(sumCatArr))]\n",
        "\n",
        "bibSubjectsCond['Unique Diversity'] = divList"
      ],
      "metadata": {
        "id": "dNIwV4_4vwV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XsUuwtdW89p"
      },
      "source": [
        "Merge Bib/Subject dataframe with record link, in order to link it to the item dataframe later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NtjMGGhXBpW"
      },
      "source": [
        "recLink = pd.merge(bibSubjectsCond, dfLinkLoad, left_on='record_num', right_on='bib_record_num').reset_index(drop=True)\n",
        "recLink = recLink.drop(['record_num'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsDBa3UX3ct"
      },
      "source": [
        "Merge this dataframe with the item df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig4Lnh1qX6nO"
      },
      "source": [
        "newItem = pd.merge(dfItemLoad, recLink, left_on='record_num', right_on='item_record_num').reset_index(drop=True)\n",
        "newItem = newItem.drop(['record_num'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2WWG5PnYsAg"
      },
      "source": [
        "Assign Fiction or NF genre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRtr8CMlYnvF"
      },
      "source": [
        "nfPat = r'((.*\\d\\d\\d.*)|(.*poetry.*)|(^jb.*))'\n",
        "NFcomp = re.compile(nfPat)\n",
        "\n",
        "GenreList = []\n",
        "GenreList = ['Nonfiction' if NFcomp.search(x) else 'Fiction' for x in newItem['call_number_norm'].astype(str)]\n",
        "newItem['Genre'] = GenreList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wxW-DeAZBws"
      },
      "source": [
        "Get branch location and audience from location code. (Some location codes are entered wrong, so filter out those with only three characters first). Then merge into the final dataframe and drop unnecessary columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcIj8uk5ZA9l"
      },
      "source": [
        "newItem = newItem[newItem['location_code'].apply (lambda x: len(str(x)) > 3)]\n",
        "\n",
        "locs = newItem.filter(['location_code'], axis=1)\n",
        "locs = locs.drop_duplicates(subset=['location_code'])\n",
        "\n",
        "AudList = []\n",
        "AudList = ['Juv' if x[3] == 'j' else 'YA' if x[3] == 'y' else 'Adult' for x in locs['location_code']]\n",
        "\n",
        "LocList = []\n",
        "LocList = ['Main' if x[2] == 'm' else 'Outreach' if x[2] == '3' else 'Boudreau' if x[2] == '4' else 'CSQ' if x[2] == '5' else 'Collins' if x[2] == '6' else \"O'Connell\" if x[2] == '7' else \"O'Neill\" if x[2] == '8' else 'Valente' if x[2] == '9' else 'Other' for x in locs['location_code']]\n",
        "\n",
        "locs['Audience'] = AudList\n",
        "locs['Location'] = LocList\n",
        "\n",
        "finalItem = pd.merge(newItem, locs, on='location_code')\n",
        "finalItem = finalItem.drop(['call_number_norm', 'location_code'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntW31rwCe1cf"
      },
      "source": [
        "Convert creation date to datetime object and get age of item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOJtP4iae5ht"
      },
      "source": [
        "finalItem['creation_date_gmt'] = pd.to_datetime(finalItem['creation_date_gmt'], utc=True)\n",
        "today = datetime.datetime.now(tz=pytz.utc)\n",
        "\n",
        "AgeList = []\n",
        "AgeList = [(today - x).days for x in finalItem['creation_date_gmt']]\n",
        "AgeListYears = [x/365 for x in AgeList]\n",
        "finalItem['Years Old'] = AgeListYears\n",
        "\n",
        "finalItem = finalItem.drop(['creation_date_gmt'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-FRwZyiivHB"
      },
      "source": [
        "Get averages for age, price, and total number of checkouts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YQ6RM5kiTBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baba0ef-ba50-4794-dbec-fd75aa0a2207"
      },
      "source": [
        "dfBud = finalItem.loc[(finalItem['Religion_Buddhism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfBudAvg = dfBud.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfBudAvg['Category'] = 'Religion_Buddhism' \n",
        "\n",
        "dfHin = finalItem.loc[(finalItem['Religion_Hinduism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfHinAvg = dfHin.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfHinAvg['Category'] = 'Religion_Hinduism'\n",
        "\n",
        "dfAth = finalItem.loc[(finalItem['Religion_Atheism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAthAvg = dfAth.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAthAvg['Category'] = 'Religion_Atheism'\n",
        "\n",
        "dfIsl = finalItem.loc[(finalItem['Religion_Islam'] > 0) & (finalItem['price'] > 0)]\n",
        "dfIslAvg = dfIsl.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfIslAvg['Category'] = 'Religion_Islam'\n",
        "\n",
        "dfChr = finalItem.loc[(finalItem['Religion_Christianity'] > 0) & (finalItem['price'] > 0)]\n",
        "dfChrAvg = dfChr.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfChrAvg['Category'] = 'Religion_Christianity'\n",
        "\n",
        "dfPag = finalItem.loc[(finalItem['Religion_Paganism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfPagAvg = dfPag.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfPagAvg['Category'] = 'Religion_Paganism'\n",
        "\n",
        "dfJud = finalItem.loc[(finalItem['Religion_Judaism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfJudAvg = dfJud.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfJudAvg['Category'] = 'Religion_Judaism'\n",
        "\n",
        "dfRel = finalItem.loc[(finalItem['Religion_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfRelAvg = dfRel.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfRelAvg['Category'] = 'Religion_General'\n",
        "\n",
        "dfCla = finalItem.loc[(finalItem['Class'] > 0) & (finalItem['price'] > 0)]\n",
        "dfClaAvg = dfCla.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfClaAvg['Category'] = 'Class'\n",
        "\n",
        "dfSA = finalItem.loc[(finalItem['Culture_SouthAsia'] > 0) & (finalItem['price'] > 0)]\n",
        "dfSAAvg = dfSA.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfSAAvg['Category'] = 'Culture_SouthAsia'\n",
        "\n",
        "dfEA = finalItem.loc[(finalItem['Culture_EastAsia'] > 0) & (finalItem['price'] > 0)]\n",
        "dfEAAvg = dfEA.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfEAAvg['Category'] = 'Culture_EastAsia'\n",
        "\n",
        "dfInd = finalItem.loc[(finalItem['Culture_Indigenous'] > 0) & (finalItem['price'] > 0)]\n",
        "dfIndAvg = dfInd.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfIndAvg['Category'] = 'Culture_Indigenous'\n",
        "\n",
        "dfHis = finalItem.loc[(finalItem['Culture_Hispanic'] > 0) & (finalItem['price'] > 0)]\n",
        "dfHisAvg = dfHis.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfHisAvg['Category'] = 'Culture_Hispanic'\n",
        "\n",
        "dfArab = finalItem.loc[(finalItem['Culture_Arab'] > 0) & (finalItem['price'] > 0)]\n",
        "dfArabAvg = dfArab.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfArabAvg['Category'] = 'Culture_Arab'\n",
        "\n",
        "dfBla = finalItem.loc[(finalItem['Culture_Black'] > 0) & (finalItem['price'] > 0)]\n",
        "dfBlaAvg = dfBla.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfBlaAvg['Category'] = 'Culture_Black'\n",
        "\n",
        "dfMul = finalItem.loc[(finalItem['Culture_Multicultural'] > 0) & (finalItem['price'] > 0)]\n",
        "dfMulAvg = dfMul.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfMulAvg['Category'] = 'Culture_Multicultural'\n",
        "\n",
        "dfBli = finalItem.loc[(finalItem['Disability_Blind'] > 0) & (finalItem['price'] > 0)]\n",
        "dfBliAvg = dfBli.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfBliAvg['Category'] = 'Disability_Blind'\n",
        "\n",
        "dfDea = finalItem.loc[(finalItem['Disability_Deaf'] > 0) & (finalItem['price'] > 0)]\n",
        "dfDeaAvg = dfDea.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDeaAvg['Category'] = 'Disability_Deaf'\n",
        "\n",
        "dfAmp = finalItem.loc[(finalItem['Disability_Amputee'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAmpAvg = dfAmp.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAmpAvg['Category'] = 'Disability_Amputee'\n",
        "\n",
        "dfDis = finalItem.loc[(finalItem['Disability_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfDisAvg = dfDis.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDisAvg['Category'] = 'Disability_General'\n",
        "\n",
        "dfAut = finalItem.loc[(finalItem['Mental_Autism'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAutAvg = dfAut.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAutAvg['Category'] = 'Mental_Autism'\n",
        "\n",
        "dfAnx = finalItem.loc[(finalItem['Mental_Anxiety'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAnxAvg = dfAnx.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAnxAvg['Category'] = 'Mental_Anxiety'\n",
        "\n",
        "dfOCD = finalItem.loc[(finalItem['Mental_Compulsive'] > 0) & (finalItem['price'] > 0)]\n",
        "dfOCDAvg = dfOCD.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfOCDAvg['Category'] = 'Mental_Compulsive'\n",
        "\n",
        "dfSch = finalItem.loc[(finalItem['Mental_Schizophrenia'] > 0) & (finalItem['price'] > 0)]\n",
        "dfSchAvg = dfSch.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfSchAvg['Category'] = 'Mental_Schizophrenia'\n",
        "\n",
        "dfEat = finalItem.loc[(finalItem['Mental_Eating'] > 0) & (finalItem['price'] > 0)]\n",
        "dfEatAvg = dfEat.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfEatAvg['Category'] = 'Mental_Eating'\n",
        "\n",
        "dfDep = finalItem.loc[(finalItem['Mental_Depression'] > 0) & (finalItem['price'] > 0)]\n",
        "dfDepAvg = dfDep.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDepAvg['Category'] = 'Mental_Depression'\n",
        "\n",
        "dfMen = finalItem.loc[(finalItem['Mental_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfMenAvg = dfMen.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfMenAvg['Category'] = 'Mental_General'\n",
        "\n",
        "dfGam = finalItem.loc[(finalItem['Addiction_Gambling'] > 0) & (finalItem['price'] > 0)]\n",
        "dfGamAvg = dfGam.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfGamAvg['Category'] = 'Addiction_Gambling'\n",
        "\n",
        "dfDru = finalItem.loc[(finalItem['Addiction_Drugs'] > 0) & (finalItem['price'] > 0)]\n",
        "dfDruAvg = dfDru.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDruAvg['Category'] = 'Addiction_Drugs'\n",
        "\n",
        "dfAlc = finalItem.loc[(finalItem['Addiction_Alcohol'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAlcAvg = dfAlc.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAlcAvg['Category'] = 'Addiction_Alcohol'\n",
        "\n",
        "dfAdd = finalItem.loc[(finalItem['Addiction_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAddAvg = dfAdd.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAddAvg['Category'] = 'Addiction_General'\n",
        "\n",
        "dfVio = finalItem.loc[(finalItem['Violence_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfVioAvg = dfVio.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfVioAvg['Category'] = 'Violence_General'\n",
        "\n",
        "dfHat = finalItem.loc[(finalItem['Violence_HateCrimes'] > 0) & (finalItem['price'] > 0)]\n",
        "dfHatAvg = dfHat.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfHatAvg['Category'] = 'Violence_HateCrimes'\n",
        "\n",
        "dfPol = finalItem.loc[(finalItem['Violence_PoliceBrutality'] > 0) & (finalItem['price'] > 0)]\n",
        "dfPolAvg = dfPol.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfPolAvg['Category'] = 'Violence_PoliceBrutality'\n",
        "\n",
        "dfTra = finalItem.loc[(finalItem['Violence_Trafficking'] > 0) & (finalItem['price'] > 0)]\n",
        "dfTraAvg = dfTra.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfTraAvg['Category'] = 'Violence_Trafficking'\n",
        "\n",
        "dfMur = finalItem.loc[(finalItem['Violence_Murder'] > 0) & (finalItem['price'] > 0)]\n",
        "dfMurAvg = dfMur.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfMurAvg['Category'] = 'Violence_Murder'\n",
        "\n",
        "dfTor = finalItem.loc[(finalItem['Violence_Torture'] > 0) & (finalItem['price'] > 0)]\n",
        "dfTorAvg = dfTor.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfTorAvg['Category'] = 'Violence_Torture'\n",
        "\n",
        "dfRap = finalItem.loc[(finalItem['Violence_Rape'] > 0) & (finalItem['price'] > 0)]\n",
        "dfRapAvg = dfRap.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfRapAvg['Category'] = 'Violence_Rape'\n",
        "\n",
        "dfAbu = finalItem.loc[(finalItem['Violence_Abuse'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAbuAvg = dfAbu.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAbuAvg['Category'] = 'Violence_Abuse'\n",
        "\n",
        "dfPho = finalItem.loc[(finalItem['Equity_Phobias'] > 0) & (finalItem['price'] > 0)]\n",
        "dfPhoAvg = dfPho.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfPhoAvg['Category'] = 'Equity_Phobias'\n",
        "\n",
        "dfSoc = finalItem.loc[(finalItem['Equity_Social'] > 0) & (finalItem['price'] > 0)]\n",
        "dfSocAvg = dfSoc.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfSocAvg['Category'] = 'Equity_Social'\n",
        "\n",
        "dfImm = finalItem.loc[(finalItem['Equity_Immigration'] > 0) & (finalItem['price'] > 0)]\n",
        "dfImmAvg = dfImm.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfImmAvg['Category'] = 'Equity_Immigration'\n",
        "\n",
        "dfGen = finalItem.loc[(finalItem['Equity_Gender'] > 0) & (finalItem['price'] > 0)]\n",
        "dfGenAvg = dfGen.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfGenAvg['Category'] = 'Equity_Gender'\n",
        "\n",
        "dfCli = finalItem.loc[(finalItem['Equity_Climate'] > 0) & (finalItem['price'] > 0)]\n",
        "dfCliAvg = dfCli.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfCliAvg['Category'] = 'Equity_Climate'\n",
        "\n",
        "dfEqu = finalItem.loc[(finalItem['Equity_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfEquAvg = dfEqu.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfEquAvg['Category'] = 'Equity_General'\n",
        "\n",
        "dfGay = finalItem.loc[(finalItem['LGBT_Gay'] > 0) & (finalItem['price'] > 0)]\n",
        "dfGayAvg = dfGay.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfGayAvg['Category'] = 'LGBT_Gay'\n",
        "\n",
        "dfBis = finalItem.loc[(finalItem['LGBT_Bisexual'] > 0) & (finalItem['price'] > 0)]\n",
        "dfBisAvg = dfBis.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfBisAvg['Category'] = 'LGBT_Bisexual'\n",
        "\n",
        "dfAse = finalItem.loc[(finalItem['LGBT_Asexual'] > 0) & (finalItem['price'] > 0)]\n",
        "dfAseAvg = dfAse.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAseAvg['Category'] = 'LGBT_Asexual'\n",
        "\n",
        "dfInt = finalItem.loc[(finalItem['LGBT_Intersex'] > 0) & (finalItem['price'] > 0)]\n",
        "dfIntAvg = dfInt.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfIntAvg['Category'] = 'LGBT_Intersex'\n",
        "\n",
        "dfTrans = finalItem.loc[(finalItem['LGBT_Trans'] > 0) & (finalItem['price'] > 0)]\n",
        "dfTransAvg = dfTrans.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfTransAvg['Category'] = 'LGBT_Trans'\n",
        "\n",
        "dfLGB = finalItem.loc[(finalItem['LGBT_General'] > 0) & (finalItem['price'] > 0)]\n",
        "dfLGBAvg = dfLGB.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfLGBAvg['Category'] = 'LGBT_General'\n",
        "\n",
        "dfRel1 = finalItem.loc[(finalItem['Unique Religion'] == 'Unique Religion') & (finalItem['price'] > 0)]\n",
        "dfRel1Avg = dfRel1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfRel1Avg['Category'] = 'Unique Religion'\n",
        "\n",
        "dfRel2 = finalItem.loc[(finalItem['Unique Religion'] == 'Not Religion') & (finalItem['price'] > 0)]\n",
        "dfRel2Avg = dfRel2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfRel2Avg['Category'] = 'Not Religion'\n",
        "\n",
        "dfClass1 = finalItem.loc[(finalItem['Unique Class'] == 'Unique Class') & (finalItem['price'] > 0)]\n",
        "dfClass1Avg = dfClass1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfClass1Avg['Category'] = 'Unique Class'\n",
        "\n",
        "dfClass2 = finalItem.loc[(finalItem['Unique Class'] == 'Not Class') & (finalItem['price'] > 0)]\n",
        "dfClass2Avg = dfClass2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfClass2Avg['Category'] = 'Not Class'\n",
        "\n",
        "dfCult1 = finalItem.loc[(finalItem['Unique Culture'] == 'Unique Culture') & (finalItem['price'] > 0)]\n",
        "dfCult1Avg = dfCult1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfCult1Avg['Category'] = 'Unique Culture'\n",
        "\n",
        "dfCult2 = finalItem.loc[(finalItem['Unique Culture'] == 'Not Culture') & (finalItem['price'] > 0)]\n",
        "dfCult2Avg = dfCult2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfCult2Avg['Category'] = 'Not Culture'\n",
        "\n",
        "dfDis1 = finalItem.loc[(finalItem['Unique Disability'] == 'Unique Disability') & (finalItem['price'] > 0)]\n",
        "dfDis1Avg = dfDis1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDis1Avg['Category'] = 'Unique Disability'\n",
        "\n",
        "dfDis2 = finalItem.loc[(finalItem['Unique Disability'] == 'Not Disability') & (finalItem['price'] > 0)]\n",
        "dfDis2Avg = dfDis2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDis2Avg['Category'] = 'Not Disability'\n",
        "\n",
        "dfMen1 = finalItem.loc[(finalItem['Unique Mental'] == 'Unique Mental') & (finalItem['price'] > 0)]\n",
        "dfMen1Avg = dfMen1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfMen1Avg['Category'] = 'Unique Mental'\n",
        "\n",
        "dfMen2 = finalItem.loc[(finalItem['Unique Mental'] == 'Not Mental') & (finalItem['price'] > 0)]\n",
        "dfMen2Avg = dfMen2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfMen2Avg['Category'] = 'Not Mental'\n",
        "\n",
        "dfAdd1 = finalItem.loc[(finalItem['Unique Addiction'] == 'Unique Addiction') & (finalItem['price'] > 0)]\n",
        "dfAdd1Avg = dfAdd1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAdd1Avg['Category'] = 'Unique Addiction'\n",
        "\n",
        "dfAdd2 = finalItem.loc[(finalItem['Unique Addiction'] == 'Not Addiction') & (finalItem['price'] > 0)]\n",
        "dfAdd2Avg = dfAdd2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfAdd2Avg['Category'] = 'Not Addiction'\n",
        "\n",
        "dfVio1 = finalItem.loc[(finalItem['Unique Violence'] == 'Unique Violence') & (finalItem['price'] > 0)]\n",
        "dfVio1Avg = dfVio1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfVio1Avg['Category'] = 'Unique Violence'\n",
        "\n",
        "dfVio2 = finalItem.loc[(finalItem['Unique Violence'] == 'Not Violence') & (finalItem['price'] > 0)]\n",
        "dfVio2Avg = dfVio2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfVio2Avg['Category'] = 'Not Violence'\n",
        "\n",
        "dfEqu1 = finalItem.loc[(finalItem['Unique Equity'] == 'Unique Equity') & (finalItem['price'] > 0)]\n",
        "dfEqu1Avg = dfEqu1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfEqu1Avg['Category'] = 'Unique Equity'\n",
        "\n",
        "dfEqu2 = finalItem.loc[(finalItem['Unique Equity'] == 'Not Equity') & (finalItem['price'] > 0)]\n",
        "dfEqu2Avg = dfEqu2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfEqu2Avg['Category'] = 'Not Equity'\n",
        "\n",
        "dfLGB1 = finalItem.loc[(finalItem['Unique LGBT'] == 'Unique LGBT') & (finalItem['price'] > 0)]\n",
        "dfLGB1Avg = dfLGB1.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfLGB1Avg['Category'] = 'Unique LGBT'\n",
        "\n",
        "dfLGB2 = finalItem.loc[(finalItem['Unique LGBT'] == 'Not LGBT') & (finalItem['price'] > 0)]\n",
        "dfLGB2Avg = dfLGB2.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfLGB2Avg['Category'] = 'Not LGBT'\n",
        "\n",
        "dfDiv = finalItem.loc[(finalItem['Unique Diversity'] == 'Unique Diverse') & (finalItem['price'] > 0)]\n",
        "dfDivAvg = dfDiv.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfDivAvg['Category'] = 'Unique Diverse'\n",
        "\n",
        "dfND = finalItem.loc[(finalItem['Unique Diversity'] == 'Not Diverse') & (finalItem['price'] > 0)]\n",
        "dfNDAvg = dfND.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])['price', 'checkout_total', 'Years Old'].mean().reset_index()\n",
        "dfNDAvg['Category'] = 'Not Diverse'\n",
        "\n",
        "frames = [dfBudAvg, dfHinAvg, dfAthAvg, dfIslAvg, dfChrAvg, dfPagAvg, dfJudAvg, dfRelAvg, dfClaAvg, dfSAAvg, dfEAAvg, dfIndAvg, dfHisAvg, dfArabAvg, dfBlaAvg, dfMulAvg, dfBliAvg, dfDeaAvg, dfAmpAvg, dfDisAvg, dfAutAvg, dfAnxAvg, dfOCDAvg, dfSchAvg, dfEatAvg, dfDepAvg, dfMenAvg, dfGamAvg, dfDruAvg, dfAlcAvg, dfAddAvg, dfVioAvg, dfHatAvg, dfPolAvg, dfTraAvg, dfMurAvg, dfTorAvg, dfRapAvg, dfAbuAvg, dfPhoAvg, dfSocAvg, dfImmAvg, dfGenAvg, dfCliAvg, dfEquAvg, dfGayAvg, dfBisAvg, dfAseAvg, dfIntAvg, dfTransAvg, dfLGBAvg, dfRel1Avg, dfRel2Avg, dfClass1Avg, dfClass2Avg, dfCult1Avg, dfCult2Avg, dfDis1Avg, dfDis2Avg, dfMen1Avg, dfMen2Avg, dfAdd1Avg, dfAdd2Avg, dfVio1Avg, dfVio2Avg, dfEqu1Avg, dfEqu2Avg, dfLGB1Avg, dfLGB2Avg, dfDivAvg, dfNDAvg]\n",
        "\n",
        "dfAvgs = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:78: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:94: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:98: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:106: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:118: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:122: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:130: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:138: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:142: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:154: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:158: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:162: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:166: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:170: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:174: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:178: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:182: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:186: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:190: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:194: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:198: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:202: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:206: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:210: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:214: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:218: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:222: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:226: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:230: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:234: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:238: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:242: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:246: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:250: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:254: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:258: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:262: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:266: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:270: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:274: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:278: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:282: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcjfsPHk90IU"
      },
      "source": [
        "Create dataframe of distinct bib records. Then convert back to boolean values. (The sum function has added up the values for each item, but to count them later on for the bibs, we just want ones and zeroes.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOuBErqS-FIr"
      },
      "source": [
        "dfDisBib = finalItem.groupby(['bib_record_num','Location','Audience','Genre','material_type_name', 'Unique Diversity', 'Unique Religion', 'Unique Class', 'Unique Culture', 'Unique Disability', 'Unique Mental', 'Unique Addiction', 'Unique Violence', 'Unique Equity', 'Unique LGBT'])[catList].sum()\n",
        "\n",
        "dfDisBib[catList] = dfDisBib[catList].astype(bool)\n",
        "dfDisBib[catList] = dfDisBib[catList].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTkF3dzw-rF6"
      },
      "source": [
        "Count total unique diverse/nondiverse bibs and put them into the Category column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WanFwvw-KVp"
      },
      "source": [
        "dfTotUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Diversity']).size().reset_index(name='Count')\n",
        "dfTotUnique = dfTotUnique.rename(columns={'Unique Diversity':'Category'})\n",
        "\n",
        "dfRelUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Religion']).size().reset_index(name='Count')\n",
        "dfRelUnique = dfRelUnique.rename(columns={'Unique Religion':'Category'})\n",
        "\n",
        "dfClassUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Class']).size().reset_index(name='Count')\n",
        "dfClassUnique = dfClassUnique.rename(columns={'Unique Class':'Category'})\n",
        "\n",
        "dfCultureUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Culture']).size().reset_index(name='Count')\n",
        "dfCultureUnique = dfCultureUnique.rename(columns={'Unique Culture':'Category'})\n",
        "\n",
        "dfDisUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Disability']).size().reset_index(name='Count')\n",
        "dfDisUnique = dfDisUnique.rename(columns={'Unique Disability':'Category'})\n",
        "\n",
        "dfMentalUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Mental']).size().reset_index(name='Count')\n",
        "dfMentalUnique = dfMentalUnique.rename(columns={'Unique Mental':'Category'})\n",
        "\n",
        "dfAddictUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Addiction']).size().reset_index(name='Count')\n",
        "dfAddictUnique = dfAddictUnique.rename(columns={'Unique Addiction':'Category'})\n",
        "\n",
        "dfViolenceUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Violence']).size().reset_index(name='Count')\n",
        "dfViolenceUnique = dfViolenceUnique.rename(columns={'Unique Violence':'Category'})\n",
        "\n",
        "dfEquityUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique Equity']).size().reset_index(name='Count')\n",
        "dfEquityUnique = dfEquityUnique.rename(columns={'Unique Equity':'Category'})\n",
        "\n",
        "dfLGBTUnique = dfDisBib.groupby(['Location','Audience','Genre','material_type_name', 'Unique LGBT']).size().reset_index(name='Count')\n",
        "dfLGBTUnique = dfLGBTUnique.rename(columns={'Unique LGBT':'Category'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sDSMFXI-wLA"
      },
      "source": [
        "Do count for categories, then transform data to long format from wide. Add in the counts for the diverse/nondiverse bibs we just did. Export to csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxs7Hsn8-Poy"
      },
      "source": [
        "dfCount = dfDisBib.groupby(['Location', 'Audience', 'Genre', 'material_type_name'])[catList].sum().reset_index()\n",
        "\n",
        "dfMelt = pd.melt(dfCount,id_vars=['Location', 'Audience', 'Genre', 'material_type_name'],var_name='Category',value_name='Count')\n",
        "\n",
        "framesDF = [dfMelt, dfTotUnique, dfRelUnique, dfClassUnique, dfCultureUnique, dfDisUnique, dfMentalUnique, dfAddictUnique, dfViolenceUnique, dfEquityUnique, dfLGBTUnique]\n",
        "dfAppend = pd.concat(framesDF, ignore_index=True)\n",
        "\n",
        "dfMerge = pd.merge(dfAppend, dfAvgs, on=['Location', 'Audience', 'Genre', 'material_type_name', 'Category']).reset_index(drop=True)\n",
        "\n",
        "dfAggs = dfMerge.rename(columns={'material_type_name':'Format', 'price':\"Avg Price\", 'checkout_total': \"Avg Total Checkouts\"})\n",
        "\n",
        "\n",
        "#I don't know why but Class is being duplicated 4 times. Drop duplicates.\n",
        "\n",
        "dfAggs = dfAggs.drop_duplicates()\n",
        "\n",
        "dfAggs.to_csv('drive/My Drive/Div Audit 11-10-22/aggregates_11-10-22.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHINuNWCx6TT"
      },
      "source": [
        "Unmount Drive to close out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_N24yhw6n0"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}